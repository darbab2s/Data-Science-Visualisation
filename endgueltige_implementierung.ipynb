{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "infinite-convention",
   "metadata": {},
   "source": [
    "# Resultierende Implementierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-draft",
   "metadata": {},
   "source": [
    "## Hier finden die Imports statt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hearing-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "from scipy import stats \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mat\n",
    "import holoviews as hv\n",
    "\n",
    "import vaex as vaex\n",
    "import vaex.jupyter.model as vjm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-access",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-gilbert",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-endorsement",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-malpractice",
   "metadata": {},
   "source": [
    "## Die Daten werden hier eingelesen.\n",
    "###### Mit Übergabe als <class 'vaex.dataframe.DataFrameArrays'> mit Ausgabe der dafür benötigten Zeit\n",
    "\n",
    "Hier wurde die Datei zwar über Pandas importiert, jedoch in Vaex übernommen, da die Vaex eigene Importierung zeitlich mehr benötigt und noch eine größere Nachbereitung als der Import von Pandas bräuchte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-trainer",
   "metadata": {},
   "source": [
    "### annotation_example1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "original-registrar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benötigte Systemzeit: 6.207s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                                    </th><th>pos_id         </th><th>barcode      </th><th>run_id  </th><th>test_date         </th><th>sign  </th><th>value  </th><th>backvalue  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i>        </td><td>&#x27;1D99900010425&#x27;</td><td>&#x27;1D9990001AA&#x27;</td><td>1       </td><td>&#x27;2011-08-02 10:08&#x27;</td><td>&#x27;n&#x27;   </td><td>102.48 </td><td>99.97      </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i>        </td><td>&#x27;1D99900010426&#x27;</td><td>&#x27;1D9990001AA&#x27;</td><td>1       </td><td>&#x27;2011-08-02 10:08&#x27;</td><td>&#x27;n&#x27;   </td><td>89.8   </td><td>106.2      </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>2</i>        </td><td>&#x27;1D99900010427&#x27;</td><td>&#x27;1D9990001AA&#x27;</td><td>1       </td><td>&#x27;2011-08-02 10:08&#x27;</td><td>&#x27;n&#x27;   </td><td>91.11  </td><td>104.31     </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>3</i>        </td><td>&#x27;1D99900010428&#x27;</td><td>&#x27;1D9990001AA&#x27;</td><td>1       </td><td>&#x27;2011-08-02 10:08&#x27;</td><td>&#x27;n&#x27;   </td><td>86.9   </td><td>107.12     </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>4</i>        </td><td>&#x27;1D99900010429&#x27;</td><td>&#x27;1D9990001AA&#x27;</td><td>1       </td><td>&#x27;2011-08-02 10:08&#x27;</td><td>&#x27;n&#x27;   </td><td>88.18  </td><td>100.59     </td></tr>\n",
       "<tr><td>...                                  </td><td>...            </td><td>...          </td><td>...     </td><td>...               </td><td>...   </td><td>...    </td><td>...        </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>3,985,915</i></td><td>&#x27;1DUMY04150201&#x27;</td><td>&#x27;1DUMY0415AE&#x27;</td><td>11      </td><td>&#x27;2012-10-27 10:10&#x27;</td><td>&#x27;n&#x27;   </td><td>90.98  </td><td>104.34     </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>3,985,916</i></td><td>&#x27;1DUMY04150202&#x27;</td><td>&#x27;1DUMY0415AE&#x27;</td><td>11      </td><td>&#x27;2012-10-27 10:10&#x27;</td><td>&#x27;n&#x27;   </td><td>103.84 </td><td>110.09     </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>3,985,917</i></td><td>&#x27;1DUMY04150203&#x27;</td><td>&#x27;1DUMY0415AE&#x27;</td><td>11      </td><td>&#x27;2012-10-27 10:10&#x27;</td><td>&#x27;n&#x27;   </td><td>109.63 </td><td>100.68     </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>3,985,918</i></td><td>&#x27;1DUMY04150204&#x27;</td><td>&#x27;1DUMY0415AE&#x27;</td><td>11      </td><td>&#x27;2012-10-27 10:10&#x27;</td><td>&#x27;n&#x27;   </td><td>100.13 </td><td>101.13     </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>3,985,919</i></td><td>&#x27;1DUMY04150205&#x27;</td><td>&#x27;1DUMY0415AE&#x27;</td><td>11      </td><td>&#x27;2012-10-27 10:10&#x27;</td><td>&#x27;n&#x27;   </td><td>125.69 </td><td>86.37      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "#          pos_id           barcode        run_id    test_date           sign    value    backvalue\n",
       "0          '1D99900010425'  '1D9990001AA'  1         '2011-08-02 10:08'  'n'     102.48   99.97\n",
       "1          '1D99900010426'  '1D9990001AA'  1         '2011-08-02 10:08'  'n'     89.8     106.2\n",
       "2          '1D99900010427'  '1D9990001AA'  1         '2011-08-02 10:08'  'n'     91.11    104.31\n",
       "3          '1D99900010428'  '1D9990001AA'  1         '2011-08-02 10:08'  'n'     86.9     107.12\n",
       "4          '1D99900010429'  '1D9990001AA'  1         '2011-08-02 10:08'  'n'     88.18    100.59\n",
       "...        ...              ...            ...       ...                 ...     ...      ...\n",
       "3,985,915  '1DUMY04150201'  '1DUMY0415AE'  11        '2012-10-27 10:10'  'n'     90.98    104.34\n",
       "3,985,916  '1DUMY04150202'  '1DUMY0415AE'  11        '2012-10-27 10:10'  'n'     103.84   110.09\n",
       "3,985,917  '1DUMY04150203'  '1DUMY0415AE'  11        '2012-10-27 10:10'  'n'     109.63   100.68\n",
       "3,985,918  '1DUMY04150204'  '1DUMY0415AE'  11        '2012-10-27 10:10'  'n'     100.13   101.13\n",
       "3,985,919  '1DUMY04150205'  '1DUMY0415AE'  11        '2012-10-27 10:10'  'n'     125.69   86.37"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_proc = time.process_time()\n",
    "\n",
    "datei_1 = pd.read_csv(\n",
    "    '/Users/samel/Documents/Hochschule/aktuelles Semester/03. Projekt zur Datenanalyse/Datein/annotation_example1.txt',\n",
    "    sep=\";\",\n",
    "    header=0\n",
    "    )\n",
    "\n",
    "datei_1 = datei_1.rename(\n",
    "    columns={'back_value                           ': 'backvalue'}\n",
    "    )\n",
    "\n",
    "df_1 = vaex.from_pandas(datei_1)\n",
    "#print(type(daten))\n",
    "\n",
    "ende_proc = time.process_time()\n",
    "print('Benötigte Systemzeit: {:5.3f}s'.format(ende_proc-start_proc))\n",
    "\n",
    "df_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-tract",
   "metadata": {},
   "source": [
    "### annotation_example2 (ursprünglich: annotation_example2-export-2020-04-30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "early-costs",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benötigte Systemzeit: 6.457s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                                    </th><th>pos_id       </th><th>barcode      </th><th>run_id  </th><th>test_date         </th><th>sign  </th><th>value  </th><th>backvalue  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i>        </td><td>1BSP201640728</td><td>&#x27;1BSP24164HL&#x27;</td><td>1       </td><td>&#x27;2013-02-01 06:02&#x27;</td><td>&#x27;s&#x27;   </td><td>65.05  </td><td>50.57      </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i>        </td><td>1BSP201640729</td><td>&#x27;1BSP24164HL&#x27;</td><td>1       </td><td>&#x27;2013-02-01 06:02&#x27;</td><td>&#x27;s&#x27;   </td><td>80.39  </td><td>120.1      </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>2</i>        </td><td>1BSP201640730</td><td>&#x27;1BSP24164HL&#x27;</td><td>1       </td><td>&#x27;2013-02-01 06:02&#x27;</td><td>&#x27;s&#x27;   </td><td>98.83  </td><td>97.27      </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>3</i>        </td><td>1BSP201640731</td><td>&#x27;1BSP24164HL&#x27;</td><td>1       </td><td>&#x27;2013-02-01 06:02&#x27;</td><td>&#x27;s&#x27;   </td><td>119.92 </td><td>124.45     </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>4</i>        </td><td>1BSP201640732</td><td>&#x27;1BSP24164HL&#x27;</td><td>1       </td><td>&#x27;2013-02-01 06:02&#x27;</td><td>&#x27;s&#x27;   </td><td>94.73  </td><td>81.88      </td></tr>\n",
       "<tr><td>...                                  </td><td>...          </td><td>...          </td><td>...     </td><td>...               </td><td>...   </td><td>...    </td><td>...        </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>4,073,467</i></td><td>1BSP800061435</td><td>&#x27;1BSP85006HH&#x27;</td><td>98      </td><td>&#x27;2013-02-05 11:02&#x27;</td><td>&#x27;s&#x27;   </td><td>108.0  </td><td>86.16      </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>4,073,468</i></td><td>1BSP800061436</td><td>&#x27;1BSP85006HH&#x27;</td><td>98      </td><td>&#x27;2013-02-05 11:02&#x27;</td><td>&#x27;s&#x27;   </td><td>99.36  </td><td>80.8       </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>4,073,469</i></td><td>1BSP800061437</td><td>&#x27;1BSP85006HH&#x27;</td><td>98      </td><td>&#x27;2013-02-05 11:02&#x27;</td><td>&#x27;s&#x27;   </td><td>78.83  </td><td>58.85      </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>4,073,470</i></td><td>1BSP800061438</td><td>&#x27;1BSP85006HH&#x27;</td><td>98      </td><td>&#x27;2013-02-05 11:02&#x27;</td><td>&#x27;s&#x27;   </td><td>122.61 </td><td>104.87     </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>4,073,471</i></td><td>1BSP800061439</td><td>&#x27;1BSP85006HH&#x27;</td><td>98      </td><td>&#x27;2013-02-05 11:02&#x27;</td><td>&#x27;s&#x27;   </td><td>307.19 </td><td>102.95     </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "#          pos_id         barcode        run_id    test_date           sign    value    backvalue\n",
       "0          1BSP201640728  '1BSP24164HL'  1         '2013-02-01 06:02'  's'     65.05    50.57\n",
       "1          1BSP201640729  '1BSP24164HL'  1         '2013-02-01 06:02'  's'     80.39    120.1\n",
       "2          1BSP201640730  '1BSP24164HL'  1         '2013-02-01 06:02'  's'     98.83    97.27\n",
       "3          1BSP201640731  '1BSP24164HL'  1         '2013-02-01 06:02'  's'     119.92   124.45\n",
       "4          1BSP201640732  '1BSP24164HL'  1         '2013-02-01 06:02'  's'     94.73    81.88\n",
       "...        ...            ...            ...       ...                 ...     ...      ...\n",
       "4,073,467  1BSP800061435  '1BSP85006HH'  98        '2013-02-05 11:02'  's'     108.0    86.16\n",
       "4,073,468  1BSP800061436  '1BSP85006HH'  98        '2013-02-05 11:02'  's'     99.36    80.8\n",
       "4,073,469  1BSP800061437  '1BSP85006HH'  98        '2013-02-05 11:02'  's'     78.83    58.85\n",
       "4,073,470  1BSP800061438  '1BSP85006HH'  98        '2013-02-05 11:02'  's'     122.61   104.87\n",
       "4,073,471  1BSP800061439  '1BSP85006HH'  98        '2013-02-05 11:02'  's'     307.19   102.95"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_proc = time.process_time()\n",
    "\n",
    "datei_2 = pd.read_csv(\n",
    "    '/Users/samel/Documents/Hochschule/aktuelles Semester/03. Projekt zur Datenanalyse/Datein/annotation_example2.txt',\n",
    "    sep=\";\",\n",
    "    header=0\n",
    "    )\n",
    "\n",
    "datei_2 = datei_2.rename(\n",
    "    columns={'back_value                           ': 'backvalue'}\n",
    "    )\n",
    "\n",
    "df_2 = vaex.from_pandas(datei_2)\n",
    "#print(type(daten))\n",
    "\n",
    "ende_proc = time.process_time()\n",
    "print('Benötigte Systemzeit: {:5.3f}s'.format(ende_proc-start_proc))\n",
    "\n",
    "df_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-cookie",
   "metadata": {},
   "source": [
    "### annotation_example3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "amazing-tumor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benötigte Systemzeit: 8.435s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                                    </th><th>pos_id         </th><th>barcode      </th><th>run_id  </th><th>test_date         </th><th>sign  </th><th>value  </th><th>backvalue  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i>        </td><td>&#x27;1001200171739&#x27;</td><td>&#x27;100129017HD&#x27;</td><td>10      </td><td>&#x27;2017-07-07 03:07&#x27;</td><td>&#x27;s&#x27;   </td><td>88.33  </td><td>131.05     </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i>        </td><td>&#x27;1001200171741&#x27;</td><td>&#x27;100129017HD&#x27;</td><td>10      </td><td>&#x27;2017-07-07 03:07&#x27;</td><td>&#x27;s&#x27;   </td><td>98.66  </td><td>95.69      </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>2</i>        </td><td>&#x27;1001200171742&#x27;</td><td>&#x27;100129017HD&#x27;</td><td>10      </td><td>&#x27;2017-07-07 03:07&#x27;</td><td>&#x27;s&#x27;   </td><td>35.03  </td><td>70.9       </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>3</i>        </td><td>&#x27;1001200171743&#x27;</td><td>&#x27;100129017HD&#x27;</td><td>10      </td><td>&#x27;2017-07-07 03:07&#x27;</td><td>&#x27;s&#x27;   </td><td>99.09  </td><td>79.79      </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>4</i>        </td><td>&#x27;1001200171744&#x27;</td><td>&#x27;100129017HD&#x27;</td><td>10      </td><td>&#x27;2017-07-07 03:07&#x27;</td><td>&#x27;s&#x27;   </td><td>82.09  </td><td>143.5      </td></tr>\n",
       "<tr><td>...                                  </td><td>...            </td><td>...          </td><td>...     </td><td>...               </td><td>...   </td><td>...    </td><td>...        </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>5,314,555</i></td><td>&#x27;1002000172921&#x27;</td><td>&#x27;100209017HD&#x27;</td><td>9       </td><td>&#x27;2017-07-07 09:07&#x27;</td><td>&#x27;s&#x27;   </td><td>88.9   </td><td>128.91     </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>5,314,556</i></td><td>&#x27;1002401401231&#x27;</td><td>&#x27;100249140HD&#x27;</td><td>9       </td><td>&#x27;2017-07-07 09:07&#x27;</td><td>&#x27;s&#x27;   </td><td>93.52  </td><td>91.56      </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>5,314,557</i></td><td>&#x27;1002401402813&#x27;</td><td>&#x27;100249140HD&#x27;</td><td>9       </td><td>&#x27;2017-07-07 09:07&#x27;</td><td>&#x27;s&#x27;   </td><td>88.53  </td><td>93.61      </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>5,314,558</i></td><td>&#x27;1BCS600562415&#x27;</td><td>&#x27;1BCS6Y056LD&#x27;</td><td>16      </td><td>&#x27;2017-08-23 09:08&#x27;</td><td>&#x27;s&#x27;   </td><td>89.24  </td><td>144.05     </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>5,314,559</i></td><td>&#x27;1002001101220&#x27;</td><td>&#x27;100209110HD&#x27;</td><td>12      </td><td>&#x27;2017-07-13 05:07&#x27;</td><td>&#x27;s&#x27;   </td><td>97.29  </td><td>73.87      </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "#          pos_id           barcode        run_id    test_date           sign    value    backvalue\n",
       "0          '1001200171739'  '100129017HD'  10        '2017-07-07 03:07'  's'     88.33    131.05\n",
       "1          '1001200171741'  '100129017HD'  10        '2017-07-07 03:07'  's'     98.66    95.69\n",
       "2          '1001200171742'  '100129017HD'  10        '2017-07-07 03:07'  's'     35.03    70.9\n",
       "3          '1001200171743'  '100129017HD'  10        '2017-07-07 03:07'  's'     99.09    79.79\n",
       "4          '1001200171744'  '100129017HD'  10        '2017-07-07 03:07'  's'     82.09    143.5\n",
       "...        ...              ...            ...       ...                 ...     ...      ...\n",
       "5,314,555  '1002000172921'  '100209017HD'  9         '2017-07-07 09:07'  's'     88.9     128.91\n",
       "5,314,556  '1002401401231'  '100249140HD'  9         '2017-07-07 09:07'  's'     93.52    91.56\n",
       "5,314,557  '1002401402813'  '100249140HD'  9         '2017-07-07 09:07'  's'     88.53    93.61\n",
       "5,314,558  '1BCS600562415'  '1BCS6Y056LD'  16        '2017-08-23 09:08'  's'     89.24    144.05\n",
       "5,314,559  '1002001101220'  '100209110HD'  12        '2017-07-13 05:07'  's'     97.29    73.87"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_proc = time.process_time()\n",
    "\n",
    "datei_3 = pd.read_csv(\n",
    "    '/Users/samel/Documents/Hochschule/aktuelles Semester/03. Projekt zur Datenanalyse/Datein/annotation_example3.txt',\n",
    "    sep=\";\",\n",
    "    header=0\n",
    "    )\n",
    "\n",
    "datei_3 = datei_3.rename(\n",
    "    columns={'back_value                           ': 'backvalue'}\n",
    "    )\n",
    "\n",
    "df_3 = vaex.from_pandas(datei_3)\n",
    "#print(type(daten))\n",
    "\n",
    "ende_proc = time.process_time()\n",
    "print('Benötigte Systemzeit: {:5.3f}s'.format(ende_proc-start_proc))\n",
    "\n",
    "df_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-georgia",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-custom",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-financing",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-cowboy",
   "metadata": {},
   "source": [
    "## Hier sollen die Dateien in Kategorien aufgeteilt werden\n",
    "##### Nebenbei werden die Dateien mit den Variablen in 'df_zahl_ohne_f' übergeben, die die Datei ohne die Werte der Kategorie 'f' besteht und verwendet werden soll."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-hobby",
   "metadata": {},
   "source": [
    "annotation_example1.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dimensional-installation",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1 = df_1[df_1.sign == 'f'] # f => failure (ein Problem mit einem der Geräte)\n",
    "\n",
    "n_1 = df_1[df_1.sign == 'n'] # n => neutral (nur Lösungsmittel, keine Substanz)\n",
    "\n",
    "p_1 = df_1[df_1.sign == 'p'] # p => positiv (kontrolle mit -max- Effekt, bzw. verschiede Konzentrationen -> DWK)\n",
    "\n",
    "z_1 = df_1[df_1.sign == 'z'] # z => zero (negative kontrolle, oder zweite kontrolle, ditto)\n",
    "\n",
    "s_1 = df_1[df_1.sign == 's'] # s => substanz (getestetes kleines chem. Molekül)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-youth",
   "metadata": {},
   "source": [
    "annotation_example2.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "reserved-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_2 = df_2[df_2.sign == 'f'] # f => failure (ein Problem mit einem der Geräte)\n",
    "\n",
    "n_2 = df_2[df_2.sign == 'n'] # n => neutral (nur Lösungsmittel, keine Substanz)\n",
    "\n",
    "p_2 = df_2[df_2.sign == 'p'] # p => positiv (kontrolle mit -max- Effekt, bzw. verschiede Konzentrationen -> DWK)\n",
    "\n",
    "z_2 = df_2[df_2.sign == 'z'] # z => zero (negative kontrolle, oder zweite kontrolle, ditto)\n",
    "\n",
    "s_2 = df_2[df_2.sign == 's'] # s => substanz (getestetes kleines chem. Molekül)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-andrew",
   "metadata": {},
   "source": [
    "annotation_example3.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "higher-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_3 = df_3[df_3.sign == 'f'] # f => failure (ein Problem mit einem der Geräte)\n",
    "\n",
    "n_3 = df_3[df_3.sign == 'n'] # n => neutral (nur Lösungsmittel, keine Substanz)\n",
    "\n",
    "p_3 = df_3[df_3.sign == 'p'] # p => positiv (kontrolle mit -max- Effekt, bzw. verschiede Konzentrationen -> DWK)\n",
    "\n",
    "z_3 = df_3[df_3.sign == 'z'] # z => zero (negative kontrolle, oder zweite kontrolle, ditto)\n",
    "\n",
    "s_3 = df_3[df_3.sign == 's'] # s => substanz (getestetes kleines chem. Molekül)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-charter",
   "metadata": {},
   "source": [
    "Hier kommt die Ausgabe der jeweiligen Längen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "literary-permit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Länge des gesamten Datensatzes aus annotation_example1.txt: 3985920 \n",
      " \n",
      "\n",
      "Länge der Kategorie f_1: 638 \n",
      "\n",
      "Länge der Kategorie n_1: 778292 \n",
      "\n",
      "Länge der Kategorie p_1: 6144 \n",
      "\n",
      "Länge der Kategorie z_1: 2368 \n",
      "\n",
      "Länge der Kategorie s_1: 3198478 \n",
      "\n",
      "Wobei wir die Kategorie 'f' vernachläsigen werden, da es sich hierbei um Gerätefehler handelt:\n",
      "3985920 - 638  = 3985282 \n",
      "\n",
      "\n",
      "\n",
      "Länge des gesamten Datensatzes aus annotation_example2.txt: 4073472 \n",
      " \n",
      "\n",
      "Länge der Kategorie f_2: 36776 \n",
      "\n",
      "Länge der Kategorie n_2: 663033 \n",
      "\n",
      "Länge der Kategorie p_2: 8329 \n",
      "\n",
      "Länge der Kategorie z_2: 0 \n",
      "\n",
      "Länge der Kategorie s_2: 3365334 \n",
      "\n",
      "Wobei wir die Kategorie 'f' vernachläsigen werden, da es sich hierbei um Gerätefehler handelt:\n",
      "4073472 - 36776  = 4036696 \n",
      "\n",
      "\n",
      "\n",
      "Länge des gesamten Datensatzes aus annotation_example3.txt: 5314560 \n",
      " \n",
      "\n",
      "Länge der Kategorie f_3: 164522 \n",
      "\n",
      "Länge der Kategorie n_3: 880350 \n",
      "\n",
      "Länge der Kategorie p_3: 7744 \n",
      "\n",
      "Länge der Kategorie z_3: 3872 \n",
      "\n",
      "Länge der Kategorie s_3: 4258072 \n",
      "\n",
      "Wobei wir die Kategorie 'f' vernachläsigen werden, da es sich hierbei um Gerätefehler handelt:\n",
      "5314560 - 164522  = 5150038 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Der kommde Bereich ist für annotation_example1.txt ausgelegt\n",
    "print('Länge des gesamten Datensatzes aus annotation_example1.txt:', len(df_1), '\\n', '\\n')\n",
    "print('Länge der Kategorie f_1:', len(f_1), '\\n')\n",
    "print('Länge der Kategorie n_1:', len(n_1), '\\n')\n",
    "print('Länge der Kategorie p_1:', len(p_1), '\\n')\n",
    "print('Länge der Kategorie z_1:', len(z_1), '\\n')\n",
    "print('Länge der Kategorie s_1:', len(s_1), '\\n')\n",
    "\n",
    "print(\"Wobei wir die Kategorie 'f' vernachläsigen werden, da es sich hierbei um Gerätefehler handelt:\")\n",
    "print( len(df_1), '-' ,len(df_1[df_1.sign == 'f']), ' =', len(s_1) + len(z_1) + len(p_1) + len(n_1), '\\n\\n\\n' )\n",
    "\n",
    "\n",
    "# Der kommde Bereich ist für annotation_example2.txt ausgelegt\n",
    "print('Länge des gesamten Datensatzes aus annotation_example2.txt:', len(df_2), '\\n', '\\n')\n",
    "print('Länge der Kategorie f_2:', len(f_2), '\\n')\n",
    "print('Länge der Kategorie n_2:', len(n_2), '\\n')\n",
    "print('Länge der Kategorie p_2:', len(p_2), '\\n')\n",
    "print('Länge der Kategorie z_2:', len(z_2), '\\n')\n",
    "print('Länge der Kategorie s_2:', len(s_2), '\\n')\n",
    "\n",
    "print(\"Wobei wir die Kategorie 'f' vernachläsigen werden, da es sich hierbei um Gerätefehler handelt:\")\n",
    "print( len(df_2), '-' ,len(df_2[df_2.sign == 'f']), ' =', len(s_2) + len(z_2) + len(p_2) + len(n_2), '\\n\\n\\n' )\n",
    "\n",
    "\n",
    "# Der kommde Bereich ist für annotation_example3.txt ausgelegt\n",
    "print('Länge des gesamten Datensatzes aus annotation_example3.txt:', len(df_3), '\\n', '\\n')\n",
    "print('Länge der Kategorie f_3:', len(f_3), '\\n')\n",
    "print('Länge der Kategorie n_3:', len(n_3), '\\n')\n",
    "print('Länge der Kategorie p_3:', len(p_3), '\\n')\n",
    "print('Länge der Kategorie z_3:', len(z_3), '\\n')\n",
    "print('Länge der Kategorie s_3:', len(s_3), '\\n')\n",
    "\n",
    "print(\"Wobei wir die Kategorie 'f' vernachläsigen werden, da es sich hierbei um Gerätefehler handelt:\")\n",
    "print( len(df_3), '-' ,len(df_3[df_3.sign == 'f']), ' =', len(s_3) + len(z_3) + len(p_3) + len(n_3), '\\n\\n\\n' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-process",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-matrix",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-cathedral",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-museum",
   "metadata": {},
   "source": [
    "## Inteervalle festlegen, um zukünftig Ausreißer entfernen zu können.\n",
    " \n",
    "### Intervalsgrenzen bestimmen\n",
    "Die Intervalle beziehen sich auf die jeweilige Kategorie (n, p, z, s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-muscle",
   "metadata": {},
   "source": [
    "annotation_example1.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sweet-south",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Intervalle sind auf die jeweiligen signs bezogen und dem entsprechenden Feature, jedoch haben diese nicht den selben Intervall, was bei der Modelierung später angepasst werden muss:\n",
      "\n",
      "n: \n",
      " VALUE: (64.76180857601881, 136.19746059287976) BACK_VALUE: (81.12422056855941, 119.28419146702588) \n",
      "\n",
      "p: \n",
      " VALUE: (-56.69870487463294, 230.73459680171612) BACK_VALUE: (-73.99608706164176, 193.5839841970584) \n",
      "\n",
      "z: \n",
      " VALUE: (-93.72026318241555, 193.71920743917232) BACK_VALUE: (-25.095635858411, 184.97798383138388) \n",
      "\n",
      "s: \n",
      " VALUE: (51.25983086360952, 132.16165014704586) BACK_VALUE: (62.17253937809675, 114.33705804917648) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Die Intervalle sind auf die jeweiligen signs bezogen und dem entsprechenden Feature, jedoch haben diese nicht den selben Intervall, was bei der Modelierung später angepasst werden muss:\\n')\n",
    "\n",
    "n_1_stdValue = n_1.std('value')\n",
    "n_1_stdBackvalue = n_1.std('backvalue')\n",
    "n_1_meanValue = n_1.mean('value')\n",
    "n_1_meanBackvalue = n_1.mean('backvalue')\n",
    "\n",
    "n_1_ValueGrenzen = ( n_1_meanValue - (3 * n_1_stdValue),\n",
    "                    n_1_meanValue + (3 * n_1_stdValue) )\n",
    "\n",
    "n_1_BackvalueGrenzen = ( n_1_meanBackvalue - (3 * n_1_stdBackvalue),\n",
    "                        n_1_meanBackvalue + (3 * n_1_stdBackvalue) )\n",
    "\n",
    "print('n:', '\\n', 'VALUE:', n_1_ValueGrenzen, 'BACK_VALUE:', n_1_BackvalueGrenzen, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "p_1_stdValue = p_1.std('value')\n",
    "p_1_stdBackvalue = p_1.std('backvalue')\n",
    "p_1_meanValue = p_1.mean('value')\n",
    "p_1_meanBackvalue = p_1.mean('backvalue')\n",
    "\n",
    "p_1_ValueGrenzen = ( p_1_meanValue - (3 * p_1_stdValue),\n",
    "                    p_1_meanValue + (3 * p_1_stdValue) )\n",
    "\n",
    "p_1_BackvalueGrenzen = ( p_1_meanBackvalue - (3 * p_1_stdBackvalue),\n",
    "                        p_1_meanBackvalue + (3 * p_1_stdBackvalue) )\n",
    "\n",
    "print('p:', '\\n', 'VALUE:', p_1_ValueGrenzen, 'BACK_VALUE:', p_1_BackvalueGrenzen, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "z_1_stdValue = z_1.std('value')\n",
    "z_1_stdBackvalue = z_1.std('backvalue')\n",
    "z_1_meanValue = z_1.mean('value')\n",
    "z_1_meanBackvalue = z_1.mean('backvalue')\n",
    "\n",
    "z_1_ValueGrenzen = ( z_1_meanValue - (3 * z_1_stdValue),\n",
    "                    z_1_meanValue + (3 * z_1_stdValue) )\n",
    "\n",
    "z_1_BackvalueGrenzen = ( z_1_meanBackvalue - (3 * z_1_stdBackvalue),\n",
    "                        z_1_meanBackvalue + (3 * z_1_stdBackvalue) )\n",
    "\n",
    "print('z:', '\\n', 'VALUE:', z_1_ValueGrenzen, 'BACK_VALUE:', z_1_BackvalueGrenzen, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "s_1_stdValue = s_1.std('value')\n",
    "s_1_stdBackvalue = s_1.std('backvalue')\n",
    "s_1_meanValue = s_1.mean('value')\n",
    "s_1_meanBackvalue = s_1.mean('backvalue')\n",
    "\n",
    "s_1_ValueGrenzen = ( s_1_meanValue - (3 * s_1_stdValue),\n",
    "                    s_1_meanValue + (3 * s_1_stdValue) )\n",
    "\n",
    "s_1_BackvalueGrenzen = ( s_1_meanBackvalue - (3 * s_1_stdBackvalue),\n",
    "                        s_1_meanBackvalue + (3 * s_1_stdBackvalue) )\n",
    "\n",
    "print('s:', '\\n', 'VALUE:', s_1_ValueGrenzen, 'BACK_VALUE:', s_1_BackvalueGrenzen, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-threat",
   "metadata": {},
   "source": [
    "annotation_example2.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-address",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dressed-flour",
   "metadata": {},
   "source": [
    "annotation_example3.txt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "other-colombia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Intervalle sind auf die jeweiligen signs bezogen und dem entsprechenden Feature, jedoch haben diese nicht den selben Intervall, was bei der Modelierung später angepasst werden muss:\n",
      "\n",
      "n: \n",
      " VALUE: (67.79281497978246, 132.71558883688144) BACK_VALUE: (-86.29620736649795, 308.5234996934131) \n",
      "\n",
      "p: \n",
      " VALUE: (-89.28200489630319, 191.30684993762543) BACK_VALUE: (-10235.07286609486, 16227.17839553701) \n",
      "\n",
      "z: \n",
      " VALUE: (-86.97366500628111, 204.09270942776868) BACK_VALUE: (-236.47778804234548, 435.3835421745769) \n",
      "\n",
      "s: \n",
      " VALUE: (34.632177276315836, 151.12981170836812) BACK_VALUE: (-410.9874897252928, 602.2923863216954) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Die Intervalle sind auf die jeweiligen signs bezogen und dem entsprechenden Feature, jedoch haben diese nicht den selben Intervall, was bei der Modelierung später angepasst werden muss:\\n')\n",
    "\n",
    "n_3_stdValue = n_3.std('value')\n",
    "n_3_stdBackvalue = n_3.std('backvalue')\n",
    "n_3_meanValue = n_3.mean('value')\n",
    "n_3_meanBackvalue = n_3.mean('backvalue')\n",
    "\n",
    "n_3_ValueGrenzen = ( n_3_meanValue - (3 * n_3_stdValue),\n",
    "                    n_3_meanValue + (3 * n_3_stdValue) )\n",
    "\n",
    "n_3_BackvalueGrenzen = ( n_3_meanBackvalue - (3 * n_3_stdBackvalue),\n",
    "                        n_3_meanBackvalue + (3 * n_3_stdBackvalue) )\n",
    "\n",
    "print('n:', '\\n', 'VALUE:', n_3_ValueGrenzen, 'BACK_VALUE:', n_3_BackvalueGrenzen, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "p_3_stdValue = p_3.std('value')\n",
    "p_3_stdBackvalue = p_3.std('backvalue')\n",
    "p_3_meanValue = p_3.mean('value')\n",
    "p_3_meanBackvalue = p_3.mean('backvalue')\n",
    "\n",
    "p_3_ValueGrenzen = ( p_3_meanValue - (3 * p_3_stdValue),\n",
    "                    p_3_meanValue + (3 * p_3_stdValue) )\n",
    "\n",
    "p_3_BackvalueGrenzen = ( p_3_meanBackvalue - (3 * p_3_stdBackvalue),\n",
    "                        p_3_meanBackvalue + (3 * p_3_stdBackvalue) )\n",
    "\n",
    "print('p:', '\\n', 'VALUE:', p_3_ValueGrenzen, 'BACK_VALUE:', p_3_BackvalueGrenzen, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "z_3_stdValue = z_3.std('value')\n",
    "z_3_stdBackvalue = z_3.std('backvalue')\n",
    "z_3_meanValue = z_3.mean('value')\n",
    "z_3_meanBackvalue = z_3.mean('backvalue')\n",
    "\n",
    "z_3_ValueGrenzen = ( z_3_meanValue - (3 * z_3_stdValue),\n",
    "                    z_3_meanValue + (3 * z_3_stdValue) )\n",
    "\n",
    "z_3_BackvalueGrenzen = ( z_3_meanBackvalue - (3 * z_3_stdBackvalue),\n",
    "                        z_3_meanBackvalue + (3 * z_3_stdBackvalue) )\n",
    "\n",
    "print('z:', '\\n', 'VALUE:', z_3_ValueGrenzen, 'BACK_VALUE:', z_3_BackvalueGrenzen, '\\n')\n",
    "\n",
    "\n",
    "\n",
    "s_3_stdValue = s_3.std('value')\n",
    "s_3_stdBackvalue = s_3.std('backvalue')\n",
    "s_3_meanValue = s_3.mean('value')\n",
    "s_3_meanBackvalue = s_3.mean('backvalue')\n",
    "\n",
    "s_3_ValueGrenzen = ( s_3_meanValue - (3 * s_3_stdValue),\n",
    "                    s_3_meanValue + (3 * s_3_stdValue) )\n",
    "\n",
    "s_3_BackvalueGrenzen = ( s_3_meanBackvalue - (3 * s_3_stdBackvalue),\n",
    "                        s_3_meanBackvalue + (3 * s_3_stdBackvalue) )\n",
    "\n",
    "print('s:', '\\n', 'VALUE:', s_3_ValueGrenzen, 'BACK_VALUE:', s_3_BackvalueGrenzen, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-holmes",
   "metadata": {},
   "source": [
    "Das hier berechnete Intervall ist im Bezug auf die gesamte Datei ohne die Kategorie 'f', wobei sich hier nicht auf das jeweilige sign bezogen wird und somit problematisch sein könnte, aber zur Modllierung im späteren Verlauf besser zu verwenden ist und somit zukünftik damit gearbeitet wird.\n",
    "Die vorherigen Intervallsgrenzen wurden zur Veranschaunlichung erstellt, um einen Vergleich bzw. Abweichung besser modelieren zu können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "great-allen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wenn wir die Intevalle der importierten Datei bestimmen, was in df gespeichert wurde, kommt folgendes dabei raus:\n",
      "    df: \n",
      "    VALUE: (38.07067313089432, 150.27277827053746) BACK_VALUE: (-713.5645279374443, 923.3391621498805) \n",
      "\n",
      "    Mittelwert von 'value': 94.17172570071568 \n",
      "    Mittelwert von 'backvalue': 104.88731710621813 \n",
      "\n",
      "\n",
      "Wir verwenden vorhin beschrieben, jedoch die Intevalle der Datei ohne der Kategorie , was in df_ohne_f gespeichert wurde und kommt folgendes dabei raus:\n",
      "    df_ohne_f: \n",
      "    VALUE: (38.07129460869005, 150.03393152750283) BACK_VALUE: (-669.3395979545287, 874.6586361363945) \n",
      "\n",
      "    Mittelwert von 'value': 94.05261306809646 \n",
      "    Mittelwert von 'backvalue': 102.65951909093293\n"
     ]
    }
   ],
   "source": [
    "df_ValueGrenzen = ( df.mean('value') - (3 * df.std('value')),\n",
    "                   df.mean('value') + (3 * df.std('value')))\n",
    "\n",
    "df_BackvalueGrenzen = ( df.mean('backvalue') - (3 * df.std('backvalue')),\n",
    "                       df.mean('backvalue') + (3 * df.std('backvalue')) )\n",
    "\n",
    "print('Wenn wir die Intevalle der importierten Datei bestimmen, was in df gespeichert wurde, kommt folgendes dabei raus:')\n",
    "print('    df:', '\\n    VALUE:', df_ValueGrenzen, 'BACK_VALUE:', df_BackvalueGrenzen, '\\n')\n",
    "print(\"    Mittelwert von 'value':\", df.mean('value'), \"\\n    Mittelwert von 'backvalue':\", df.mean('backvalue'), '\\n\\n')\n",
    "\n",
    "\n",
    "\n",
    "df_ohne_f_ValueGrenzen = ( df_ohne_f.mean('value') - (3 * df_ohne_f.std('value')),\n",
    "                          df_ohne_f.mean('value') + (3 * df_ohne_f.std('value')))\n",
    "\n",
    "df_ohne_f_BackvalueGrenzen = ( df_ohne_f.mean('backvalue') - (3 * df_ohne_f.std('backvalue')),\n",
    "                              df_ohne_f.mean('backvalue') + (3 * df_ohne_f.std('backvalue')) )\n",
    "\n",
    "print('Wir verwenden vorhin beschrieben, jedoch die Intevalle der Datei ohne der Kategorie 'f', was in df_ohne_f gespeichert wurde und kommt folgendes dabei raus:')\n",
    "print('    df_ohne_f:', '\\n    VALUE:', df_ohne_f_ValueGrenzen, 'BACK_VALUE:', df_ohne_f_BackvalueGrenzen, '\\n')\n",
    "print(\"    Mittelwert von 'value':\", df_ohne_f.mean('value'), \"\\n    Mittelwert von 'backvalue':\", df_ohne_f.mean('backvalue'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-student",
   "metadata": {},
   "source": [
    "=> Daraus ist erkenntlich, dass für den 'value' ein geringer Unterschied besteht ob der sign 'f' mit betrachtet wird oder nicht, wo hingegen es beim 'backvalue' es einen größeren Unterschied macht. Es werden zwar wenn wir die einzelnen sign's nochmal betrachten, einen Unterschied machen, ob wir sie zusammenhängend oder einzelnd betrachten, indem besipielsweise von den sign's n, z und s mehr Werte mit übernommen und betrachtet, wo es beim p so ist, dass es weniger werte sind, die betrachtet werden.\n",
    "\n",
    "Um es genauer Auszudrücken: Das betrachten der Intervallsgrenzen der Datei ohne der Kateegorie 'f' sorgt dafür, dass wir 4995633 Zeilen von den gesamten 5314560 haben, wenn wir jedoch die Kategorien einzeln betrachtet und derren Zeilen zusammengefügt hätten, wären es stattdessen 4992498, was eine Abweichung von 3135 Zeilen ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lucky-turner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  df_without_f: 5150038 => df_cleaned_without_f: 4995633\n"
     ]
    }
   ],
   "source": [
    "df_cleaned_without_f = df_ohne_f[(df_ohne_f['value'] <= df_ohne_f_ValueGrenzen[1] )\n",
    "                                 & (df_ohne_f['value'] >= df_ohne_f_ValueGrenzen[0] )\n",
    "                                 & (df_ohne_f['backvalue'] <= df_ohne_f_BackvalueGrenzen[1] )\n",
    "                                 & (df_ohne_f['backvalue'] >= df_ohne_f_BackvalueGrenzen[0] )\n",
    "                                ]\n",
    "\n",
    "print('  df_without_f:', len(df_ohne_f), '=> df_cleaned_without_f:', len(df_cleaned_without_f))#, '\\n    -> Der Wert unterscheidet sich um', len(df_cleaned_without_f)-gesamt_anz, 'im verhältis zu der Menge, wo die signs einzeln betrachtet wurden.', '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-installation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worldwide-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from fcmeans import FCM\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-ownership",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-tourist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
